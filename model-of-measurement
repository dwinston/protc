being:reality:universe = the full 4d(?) universe
being-subset = 
s-relevant:s-measured??
s-measured:subset-measured:being-measured:being-subset-measured:s-image
s-prior: -dependent: -protocol: -dependency: -causal
measure:
Ω-measure:omega-measure:total-measure
agent-measure
relevant-measure
symbol:symbolic-rep:symbolic representation
state:
agent:executor
movement:energy dissapation:"causal" state transition:energy-matter-interconversion
existence:the eternal
implementation:representation  ; is this a conflation of two things? ... how to bring something into being exactly vs symbolically maybe?, one deals with existence <-> symbol (representation) the other being <-> symbol ARGH SO HARD TO THINK ABOUT CLEARLY
implement:execute:actualize = take a symbolic-representation of some being-subset and bring it into being
record:instantiate:represent = take a symbolic-representation of some non-being existence and bring it into being
alpha-record:α-record = the record function that when given the exact symbolic representation of a subset of being returns that subset, when given an incomplete (uncertain) symbolic representation of that being it returns bottom, inverse of omega-measure
tau:get-time-interval
invariant:
⊥:bottom:\bot:
->:evaluates-to
protocol = a specification for a being-subset that produces a semi-known being-subset (allows the inference of a subset of the state without actually having to call measure on it) ; find a better way to say this

; predicates
measureable?
implementable?
representable?
state?


(measure being) -> bottom
(record (omega-measure being)) -> being ; some fun comments about the computational complexity of being here...
(measure being-subset) -> symbol ; putting causal bounds on subsets...
(record symbol) -> representation
(= (alpha-record (omega-measure being-subset)) being-subset) -> #t ; subsets are implementations of the symbols of themselves
(record (measure subset)) ; science, ignoring the implementation details
(protocol s-prior) -> s-related inferred-state ; need something more for inferred-state...

measure <-agent-> movement/energy dissipation implies that any subset of the universe that takes in
energy/particle/matter and emits photos at a lower energy could be considered to be an agent (hrm... where
do black holes fit in here... something to do with the timescale of reemission... or maybe the implementation
of a measurement...)

Theorem 1: s-relevant is always bounded IF you are willing to specify a non-zero uncertainty/finite
precision. This holds for universes where the underlying reality has a finite starting point (ie not
doubly infinite in time, or where there is a (space/)time singularity a few years back) and where
there is a speed limit (c) aka where there is locality. In universes without locality this theorem
might still hold if there were something like the 2nd law of thermodynamics that prevented non-locality
from magically popping in and messing with results (a cost function with distance or something). It may
just be a requirement that the causal topology of the underlying reality be connected, meaning that
causes cannot 'jump' from one part of reality to the next without passing through the intervening bits.
Is it even possible to make measurements in non-local universes, probably, which means that simply being
able to transform s-measure into a symbol is not sufficient to satisfy T1. The intuition for this in
local, starting universes is that there is a finite amout of time that can cause events (ignoring the
future causal entanglement stuff for the moment) and the speed limit provides the classic light cone
in space that places a finite limit on the distance from which other parts of the universe can effect
each other. The evidence supporting a variety of R^2 phenomena also provide much stronger constraints
on the bounds for s-relevant. (If information can leak from one universe to the next through the starting
singularity I'm going to be super pissed here.)

Independent of the underlying time constants of being processes (taus, temporal variability) are all
primitive (being) measurements effectively instantaneous? That is, is there any process of measurement
that can produce a number that is the product of multiple points in time. I want to say that there is
root mean squared measurements of AC current seem like the natural candidate, the question is whether
RMS is actually a primitive measure. The transition from being -> existence (symbolization) is most
definitely instantaneous, so in that sense calling (measure being-subset) is instantaneous? Need to
think about this and the implications one way or another.

Is naming a type of high level/complex measurement function (perhaps ill-specified)? Traditional naming
definitely relies on a number of black box measurements (eg visual processing, olfactory processing)
and produces a symbol at the other end. This is not all that different from a number that is produced
by a thermocouple when you have no idea that it is a thermocouple that measures the temperature nor
an inkling about the principles underlying it nor the ability to build one. The only difference would
seem to be the number of black box steps, or more simply the magnitude of our ignorance. This leads
directly to a correlary which is 'what is the error of naming?' If naming is a measure then it MUST
be possible to measure whether it was assigned correctly, either by comparison to a type specimine or
by comparison to an average of all named specimines. I'm going to go with NO it is NOT a measurement
because there is nothing in the underlying being that can be represented by the name that is given.
The name is a function from symbols to symbols NOT from being -> symbols. There is no being measure
that can produce a name.

What is a being measure? What is a computed measure?
Computed measures produce numbers that have been modified acording to (intensional) symolic operations,
even if they are implemented in hardware (eg the output of the gain step of a dsp). In contrast being
measures are the first available symbolically representable state of underlying being. For example the
analog voltage measured across a known resistor PRIOR to digitization so that digitization aliasing
can be accounted for in the provenance. Not entirely sure how to make this kind of distinction practical
in protc or anything else that implements this model of measurement. I don't think there is an issue
with also allowing the digitized signal to be the 'first' symbolic representation since often in science
we might no know that there is a prior phenomenon that underlies what we think we are measuring. [Fun times
trying to document the 'historical' protocols that were used to develop standard measures. I wonder if the
protocols look like fixed points or whether they simply piggy back on local (assued) invariants in the
structure of being? The process needed to FIND the invariants will probably look different depending on
the type of invariant and the types of noise it is subject to. The notion that an invariant exists in
the first place should hopefully bear more similarity. Unfortunately this theory of measurement models
hypotheses as if they spring from the Void itself (they might as well).]


; assumptions
	In the best case we want a theory of measurement to make zero assumptions about the nature of the underlying being [reality] we are trying to measure.
	Unfortunately there are some assumptions that are unavoidable when we impose measurement on being.
	All assumptions we make about the underlying nature of being in this theory are equivalent to the assumption that it is possible to take an omega-measure on being.
	Phrased another way: symbols that represent all of being are contained in the class of existences.
	(contains (omega-measure being) existence) -> #t
; implications of assumptions
	Electrons have positions and momentums at the same time, even if we cannot measure them at the same time.
	Note here that the relationship between knowability within the universe and the true nature of being are quite distinct. ; more considerations about proabalistic 'state' here... (ie that Heisenberg's is a statement about knowability/measureability not about being, see evidence that Cochlea allow humans to perform better than expected on the uncertainty principle imposted by the fourier transform)
	That it is possible to recover the string of random numbers that actually came out of the universe's RNG.

; ramblings
	We can never know whether we have obtained an omega-measure.
	The best we can hope to achieve is a relevant-measure, and
	relevant-measure is always defined by a set of axioms, not by being.
	Essentially, there is no oracle that we can use to check our answers,
	there is no revealed truth that can tell us the nature of being.

	Frank makes a good point about 'aximomatic knowability' vs 'scientific knowability'
	I disagree that being able to infer things about the structure of the universe
	prior to the big bang actually counts as being able to infer things about other universes,
	because it is not clear to me that we can *actually* consider singularities to be outside
	being (as much as I might like to for convenience sake). Certainly it wouldn't meet even
	relaxed	criteria for scientific knowability because there is no way to make a direct
	measurement on more than one member of the class of universes leaving us with the n=1 problem.

; todo
	Is it actually possible to constrain the bounds of s-relevant? Yes, but only as a function of a set of axioms (and perhaps data at some point).
	Measuring the voltage between ground and probe sticking things in between the two produces a symbol which represents an extremely complex 'state' variable, and might even be said to only refer to the state of the digitizer or the state of the transistors in the cpu, which is circular and severely unsatisfactory. In this case there is a mental model that can help constrain the problem: a circuit. However, in many cases, and certainly at the start of any new science, those models do not exist or must be imported (as axioms) from some already existing field of knowledge.
